# -*- coding: utf-8 -*-
"""doMusicAndSpeechDetection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/satvik-venkatesh/audio-seg-data-synth/blob/main/models/doMusicAndSpeechDetection.ipynb
"""

import numpy as np
import tensorflow as tf
import math
from tensorflow import keras
from tensorflow.keras import layers


class MusicSpeechClass():
  
  def __init__(self, params):
    
    self.model = self.build_model()
    self.model.load_weights(params.model_weights_file)
  
    self.params = params
  
  def build_model(self):
    
    mel_input = keras.Input(shape=(802, 80), name="mel_input")
        
    X = layers.Reshape((802, 80, 1))(mel_input)

    X = layers.Conv2D(filters=16, kernel_size=7, strides=1, padding='same')(X)
    X = layers.BatchNormalization(momentum=0.0)(X)
    X = layers.Activation('relu')(X)
    X = layers.MaxPool2D(pool_size=(1, 2))(X)
    X = layers.Dropout(rate = 0.2)(X)

    X = layers.Conv2D(filters=64, kernel_size=7, strides=1, padding='same')(X)
    X = layers.BatchNormalization(momentum=0.0)(X)
    X = layers.Activation('relu')(X)
    X = layers.MaxPool2D(pool_size=(1, 2))(X)
    X = layers.Dropout(rate = 0.2)(X)

    _, _, sx, sy = X.shape
    X = layers.Reshape((-1, int(sx * sy)))(X)

    X = layers.Bidirectional(layers.GRU(80, return_sequences = True))(X)
    X = layers.BatchNormalization(momentum=0.0)(X)

    X = layers.Bidirectional(layers.GRU(80, return_sequences = True))(X)
    X = layers.BatchNormalization(momentum=0.0)(X)

    pred = layers.TimeDistributed(layers.Dense(2, activation='sigmoid'))(X)

    model = keras.Model(inputs = [mel_input], outputs = [pred])

    return model

  def predict(self, input_data):

    oop = self.model.predict(input_data)

    return oop
